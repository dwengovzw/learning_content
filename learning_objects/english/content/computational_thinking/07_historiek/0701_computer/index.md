---
available: true
content_location: example-location
content_type: text/markdown
copyright: dwengo
description: Computer
difficulty: 3
educational_goals:
- id: id
  source: Source
- id: id2
  source: Source2
estimated_time: 1
hruid: ct07_01
keywords:
- ''
language: en
licence: dwengo
return_value:
  callback_schema:
    att: test
    att2: test2
  callback_url: callback-url-example
skos_concepts:
- http://ilearn.ilabt.imec.be/vocab/curr1/s-computers-en-systemen
target_ages:
- 12
- 13
- 14
- 15
- 16
- 17
- 18
teacher_exclusive: true
title: Computer
version: 3
---
# Computer

In the 19th century, Joseph-Marie Jacquard designed a loom whose pattern was 'programmed' into the device with **(binary) punch cards**. His contemporary Charles Babbage built the Difference Engine, which could automatically generate logarithm tables and sine tables. He then spent years developing the Analytical Engine, a more general (mechanical) computer, which he never built, but for which Ada Lovelace did publish the first computer program (Denning & Tedre, 2019). 

> Binary representation of data is one of the foundations of modern computers. 
> To input the data and the instructions into the machine, Babbage wanted to use punch cards. 

The great merit of Lovelace is that she understood that a computer could do other things besides calculating. If, e.g., musical notes were represented by numbers, the machine could make music (Wolfram, 2015). 

> Lovelace published a program to compute the Bernoulli numbers. It already contained all the important principles of a computer program, such as binary representation, input, processing, output, memory, sequence, iteration and selection structures (Wolfram, 2015). 

Logic is a discipline that goes back to antiquity and studies reasoning. George Boole, also in the 19th century, sought a symbolic language to formalize rules from logic. His theory was later complemented by Gottlob Frege with predicate logic. Claude Shannonâ€™s insight (first half of the 20th century) that this Boolean algebra could serve to reason about electrical circuits was a great step forward: it meant that one could switch from mechanical to electronic systems (Denning & Tedre, 2019). 

Engineers then applied insights from mathematics, logic, and engineering to build computers. The first computer was built in 1938 by the German Konrad Zuse and used binary numbers. In the US, the computer made its entrance in 1944: the Mark I by Howard Aiken (Denning & Tedre, 2019). The first electronic computers were the Colossus in the UK (1943) and the ENIAC (1945) in the US, but they were less easy to program. The SSEM (Small-Scale Experimental Machine) from the University of Manchester in 1948, also called the "Baby", was the first electronic, digital computer that could not only store data but also store and execute a short program from a user (Napper, 1998).

**Frustrations over the lack of user-friendliness and the desire to deploy the computer faster, better, and at a larger scale led to ever faster and more reliable devices and to more intuitive programming languages.** 

<div class="alert alert-box alert-success">
<strong><h5>Accessibility</h5></strong>
Just as mathematical algorithms ensure that more people can perform certain calculations without errors, accessible programming languages and better computers lead to <em>more people</em> discovering the possibilities that computers offer them. This would not be possible without certain facets of <em>computational thinking</em>: thinking about how to avoid errors, identifying and remedying limitations in the systems and in the software, and bringing together knowledge from different disciplines (Denning & Tedre, 2019).
</div>

Thus the simple calculating devices of the 17th century evolved into the computers we know today.