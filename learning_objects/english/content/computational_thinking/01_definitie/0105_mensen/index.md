---
available: true
content_location: example-location
content_type: text/markdown
copyright: dwengo
description: 'Point of attention: People'
difficulty: 3
educational_goals:
- id: id
  source: Source
- id: id2
  source: Source2
estimated_time: 1
hruid: ct01_05
keywords:
- ''
language: en
licence: dwengo
return_value:
  callback_schema:
    att: test
    att2: test2
  callback_url: callback-url-example
skos_concepts:
- http://ilearn.ilabt.imec.be/vocab/curr1/s-computers-en-systemen
target_ages:
- 12
- 13
- 14
- 15
- 16
- 17
- 18
teacher_exclusive: true
title: 'Point of attention: People'
version: 3
---
# Points of attention

## People
Computational thinking is about people. 

- Digital applications are made by and for people, and used by people.

- According to Lowe & Brophy (2017), almost every digital system is part of a larger system in which **people are central**. 

- Wing (2006), who put computational thinking on the global agenda, mentioned **“understanding human behavior”** as one of the aspects of computational thinking. 

- Using computers is also a social activity in which one must take into account their role in **society** (Kafai and Proctor, 2022).

You cannot view a new digital application separately from the person who developed it, the person who will use it, and the society in which it will end up.

The deployment of new technologies often brings **ethical concerns** with it.

-  How do people respond to new technologies and how do they deal with them (Lowe & Brophy, 2017; Curzon & McOwan, 2017; Bell, 2018)?

-  Are cultural differences and ethical aspects taken into account when developing new digital systems (Denning & Tedre, 2019)?

-  How do we deal with cultural bias in computer systems (Kafai and Proctor, 2022)?

> You can read more about the ethical aspects of new technological applications in the guides for the projects ‘KIKS’, ‘AI in Healthcare’ and ‘Chatbot’ from AI Op School. See [dwengo.org](https://dwengo.org "website").

When designing a new system, it is best to involve the people who will have to work with it, so that a device, for example, is sufficiently user-friendly, and an AI system, for example, does not discriminate. In this way, one also hopefully does not overlook possible human behavior, as with the Twitter bot Tay. 

> Tay was initially built for entertainment, but was used in a completely different way. Tay was spreading hate speech after just a few hours and was therefore quickly taken offline (Neff & Nagy, 2016).<br> You can find more about Tay in the [guide for the project ‘Chatbot’](https://www.dwengo.org/chatbot "chatbot") from AI Op School.