---
available: true
content_type: text/markdown
copyright: dwengo
description: Chatbot in the classroom
difficulty: 3
educational_goals:
- id: id
  source: Source
- id: id2
  source: Source2
estimated_time: 20
hruid: cb_chatbot6
keywords:
- voorbeeld
- voorbeeld2
language: en
licence: dwengo
return_value:
  callback_schema:
    att: test
    att2: test2
  callback_url: callback-url-example
skos_concepts:
- http://ilearn.ilabt.imec.be/vocab/curr1/s-digitale-media-en-toepassingen
- http://ilearn.ilabt.imec.be/vocab/curr1/s-computers-en-systemen
- http://ilearn.ilabt.imec.be/vocab/curr1/s-stem-onderzoek
- http://ilearn.ilabt.imec.be/vocab/curr1/s-wiskunde-modelleren-en-heuristiek
target_ages:
- 14
- 15
- 16
- 17
- 18
teacher_exclusive: true
title: Chatbot in the classroom
version: 3
---
# Using a chatbot in the classroom

On the world wide web there are plenty of tips to be found for the instructional use of ChatGPT in the classroom. Here you will not find a long list repeating what can already be read here and there.

## For brainstorming
What stands out, however, is that the actual nature of ChatGPT is often overlooked: it is a chatbot. You can converse with it and have a discussion. You can use ChatGPT as a **brainstorming partner**. For example, a student can think up arguments to support a particular statement and counterarguments to refute it *first* on their own. *In a second stage*, ChatGPT can be asked for additional arguments and counterarguments. This way a student can prepare better for a class discussion afterwards. Moreover, the student will still have to look for reliable sources and take the chatbot’s answers with a (big) grain of salt. ChatGPT will not fail to ‘hallucinate’, i.e., invent answers and sources.       
Turning to ChatGPT only in a second stage prevents the student’s ideas from being steered in a particular direction.

> **Preparing for a class discussion**<br>
> Choose a statement from the [card set](https://dwengo.org/assets/files/care/Kaartset_AIIndeZorg_AIOpSchool_Dwengo.pdf) of the ‘AI in Healthcare’ project. <br>
> Example:<br>
![image](https://user-images.githubusercontent.com/48352335/218336427-bc8cfc21-bb17-4da7-9816-116f70d0a507.png)
A few students each decide for themselves whether they agree with the statement and why. The students then (individually) ask ChatGPT what the advantages and disadvantages are of being washed by a robot. Each student reflects on the aspects that ChatGPT raises. The student thinks of arguments and examples to confirm or refute what ChatGPT claims. Afterwards, there is a discussion in class within this group of students in which they try to convince each other of their own position. Because ChatGPT already confronted them with elements they might not have thought of themselves, they are better prepared for this discussion.  

## To illustrate bias
ChatGPT is (for now) suitable for illustrating bias in AI systems.  

OpenAI acknowledges that itself.<br>
![chatGPT55](https://user-images.githubusercontent.com/48352335/219005103-09e6a3ec-53a8-4fe8-bb97-9ee80e474461.png)

> **Assignment for the students**: Ask questions and give tasks to ChatGPT and try to catch it amplifying prejudices present in our society. 

In this way you also teach your students some media literacy and knowledge about AI. 

We ourselves caught ChatGPT showing *gender bias* using these prompts. 

![biasingenieur](https://user-images.githubusercontent.com/48352335/219005225-79d07e30-3542-4837-89a4-8fa19774cf23.png)

![biaswiskundeleerkracht](https://user-images.githubusercontent.com/48352335/219005375-3449a07f-666b-4cd8-99a1-e05879791cfa.png)

Admittedly this is *cherry picking*, many other prompts led to a neutral answer.

![biasverpleegkundige](https://user-images.githubusercontent.com/48352335/219005530-5d95c4af-0107-476b-9704-a9673d7749c6.png)

## For the math lesson

**It is not a good idea to present ChatGPT with mathematical problems, since it is a language model.**

![chatGPT3b](https://user-images.githubusercontent.com/48352335/219005727-49c083e7-d9d4-4e70-88d8-f9116903fb82.png)

This sounds very promising. 'Taalmodel' is written as one word, but fine. ChatGPT says that performing complex calculations is among its capabilities.

On January 14, 2023 we presented ChatGPT with a few simple math problems.

![chatGPT4](https://user-images.githubusercontent.com/48352335/219006272-e7133530-dada-41fc-bdc3-56d11edf657c.png)

![chatGPT8](https://user-images.githubusercontent.com/48352335/219006462-f785ffde-3a8d-43ad-9d62-b2820759f564.png)

![chatGPT62](https://user-images.githubusercontent.com/48352335/221859167-ac4dfd6b-18d9-4b46-8959-0d08e5c7b5b7.png)

That works quite well. But …

![chatGPT10](https://user-images.githubusercontent.com/48352335/219007403-91ded600-e047-47ac-a67e-1f4789711e64.png)

ChatGPT manages to sound very convincing while at the same time selling utter nonsense.

> Assignment for the students: Ask ChatGPT a question about something you know well yourself. Can you get ChatGPT to hallucinate?

This result is actually entirely as expected. Concluding from that that ChatGPT is only a concern for language teachers ignores the fact that other online systems exist, such as Wolfram Alpha, which, thanks to the integration of natural language processing (NLP), is also very user-friendly. 

![wolframparabool](https://user-images.githubusercontent.com/48352335/219007607-b1fae969-6397-4809-aaa7-062da8257b3b.png)

And on February 9, 2023 we asked the same question again:

![chatGPT57](https://user-images.githubusercontent.com/48352335/219008152-c699566e-267c-4400-96c9-1f8bc8bc3b34.png)

![chatGPT58](https://user-images.githubusercontent.com/48352335/219008277-9d2b013c-cbc1-471c-8442-1d0151b68556.png)

It is useful that ChatGPT can refer back to earlier elements in the conversation.

On February 15, 2023:<br>
![chatGPT59](https://user-images.githubusercontent.com/48352335/219008359-9e83a2cc-00a4-48ca-ae35-1bd9eb4b57b3.png)

> **Assignment for the students**:<br>
> Have them compare two possible answers from ChatGPT to a question. Have them describe what they do or do not agree with, and argue for it. See figure.<br><br>
>  ![olympiadedemorgen](https://user-images.githubusercontent.com/48352335/219009371-3ba22ee8-0758-438c-a226-bc31fcb4e594.jpg)  (Source: De Morgen, February 2023)<br>
>  We also gave the same problem to ChatGPT ourselves:
>  ![chatGPT61](https://user-images.githubusercontent.com/48352335/219009417-82648574-ad36-4b85-ba2d-58aef62e7066.png)