---
hruid: ct9_5
version: 3
language: nl
title: "Solliciteren"
description: "Solliciteren"
keywords: [""]
educational_goals: [
    {source: Source, id: id}, 
    {source: Source2, id: id2}
]
copyright: dwengo
licence: dwengo
content_type: text/markdown
available: true
target_ages: [12, 13, 14]
difficulty: 3
return_value: {
    callback_url: callback-url-example,
    callback_schema: {
        att: test,
        att2: test2
    }
}
content_location: example-location
estimated_time: 1
skos_concepts: [
    'http://ilearn.ilabt.imec.be/vocab/curr1/s-computers-en-systemen'
]
teacher_exclusive: true
---

# Solliciteren

Kijk naar [Filmpje van Kanaal Z (De Winne, 2020)](https://kanaalz.knack.be/nieuws/taalgebruik-op-cv-onthultpersoonlijkheid/video-normal-1678309.html)


Bekijk de [video van Furhat Robotics: Unbiased Recruiter Robot (Furhat Robotics, 2018)](https://youtu.be/rPKrdxiEkQ0)



**Impact: Nieuwe manieren van solliciteren**<br>

Dankzij AI kan men op sommige platforms interessante vacatures in de mailbox krijgen. Maar krijgt men
wel alle vacatures te zien waarin men geïnteresseerd
is? Tot 2018 gebruikte Amazon een sterk bejubeld maar
ondertussen afgevoerd AI-systeem om sollicitanten te
beoordelen. Het systeem selecteerde geen vrouwen
voor technologische posities. Het was immers getraind
met historische data: sollicitanten van de voorbije 10
jaar, voornamelijk mannen aangezien zij nog steeds de
technologiewereld domineren. Een Gents bedrijf werkt
aan een AI-systeem dat uit sollicitatiebrieven beslist in
welke mate de auteur geschikt is voor de job. Het systeem leidt daartoe persoonlijkheidskenmerken af uit wat
de sollicitant schreef. Sommige bedrijven maken om
nieuw personeel aan te werven, gebruik van een videointerview, dat ganalyseerd wordt door een algoritme.
Daarbij wordt niet enkel rekening gehouden met wat
de sollicitant zegt, maar ook met gelaatsuitdrukkingen
bijvoorbeeld.

Zal er in de toekomst nog op de klassieke manier gesolliciteerd worden? Waarschijnlijk niet. Solliciteren is
eigenlijk al grondig veranderd toen werkgevers toekomstige werknemers zijn beginnen te screenen op sociale
media.

In het Chatbot-project worden voorbeelden gegeven van nieuwe praktijken die steeds
meer hun weg vinden naar de sector van human resource, zoals het screenen van
sociale media. Leerlingen beseffen dat wat op socialemediaplatformen gepost wordt, er
binnen enkele jaren als zij gaan solliciteren nog steeds te vinden is.

Maar het gaat al veel verder dan dat. Unilever bijvoor- Bekijk de video ‘The Robots Are
Now Hiring’ (zie Kijktip). beeld, start een sollicitatieprocedure met het verplicht
indienen van een filmpje, wat dan door een AI-systeem
wordt geanalyseerd. Men zegt dat het systeem er de
meest gemotiveerde en geschikte kandidaten voor de
job uithaalt (Oostra, 2019; Wall Street Journal, 2018).
Het Gentse bedrijf Traicie werkt aan een AI-systeem
dat op basis van sollicitatiebrieven beslist in welke mate
de auteur over de vaardigheden beschikt vereist voor
een bepaalde job. Het systeem leidt daartoe persoonlijkheidskenmerken af uit wat de sollicitant schreef en
zegt daarvoor een unbiased systeem te gebruiken.
Voor human resources is de persoonlijkheid van een
sollicitant een interessant gegeven, sommige types zijn
immers beter geschikt voor een bepaalde functie dan
andere (De Gussem & Daelemans, 2020).

> **Leestips:**<br>



Bekijk de video (De Winne, 2020):
https://kanaalz.knack.be/nieuws/taalgebruik-op-cv-onthultpersoonlijkheid/video-normal-1678309.html.
Bezoek ook de website https://traicie.com/ en bespreek de objectiviteit
van het systeem.

In de volgende video worden de nieuwe tendensen bij het aanwerven van
personeel aangehaald (Wall Street Journal, 2018):
https://youtu.be/8QEK7B9GUhM
Bespreek.

## Principes van computationeel denken

![ct-schema](@learning-object/m_ct_impact_5/nl/3)
 
## Bespreking van de impact

-  
    - 


Bias komt voor als de data niet representatief zijn. Als men bv. enkel groene
appels als voorbeelden geeft aan een DL-systeem, dan zal het model geen
rode appels herkennen. Of als men bij de training enkel foto’s van honden
onder een stralend blauwe hemel aanbiedt, dan zal het DL-model een hond in
de regen niet bij de klasse ’hond’ indelen. Als de gebruikte data gekleurd zijn
door een aanwezige bias in de maatschappij, zoals stereotypen, dan zal dit ook
doorgegeven worden aan het ML-systeem. Men moet er dus over waken dat
het model daardoor niet discriminerend wordt voor bepaalde bevolkingsgroepen.
Als men bv. enkel vrouwelijke verplegers in de dataset stopt, dan zullen mannen
niet als verpleger worden geclassificeerd. Een model wordt nochtans getest
voor het in gebruik genomen wordt. De testdata kunnen echter dezelfde bias
bevatten als de trainingdata.

-------------------------------
## Gerelateerde voorbeelden: 

-----------------------------
### Werking 
In het leerpad '' wordt [de werking] uit de doeken gedaan.

-----------------------------
#### Leestips



#### Kijktips
